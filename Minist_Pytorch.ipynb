{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNOGbAEW41UeZ9E9KOQH/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmdedavoodi/mnist-pytorch-classifier/blob/main/Minist_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxkKjfdkkAoi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize(0.13 , 0.31),\n",
        "                                      transforms.RandomRotation(30),\n",
        "                                      transforms.RandomAffine(10 , translate= (0.1 , 0.1))\n",
        "                                     ])\n",
        "transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize(0.13 , 0.31)])\n",
        "\n",
        "\n",
        "dataset_train = torchvision.datasets.MNIST(root=\"data\",\n",
        "                                           train = True,\n",
        "                                           download = True,\n",
        "                                           transform = transform_train)\n",
        "\n",
        "dataset_test = torchvision.datasets.MNIST(root=\"data\",\n",
        "                                           train = False,\n",
        "                                           download = True,\n",
        "                                           transform = transform_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "yDd--1jdkL3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train"
      ],
      "metadata": {
        "id": "e9zeO8ULMegK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test DataSet"
      ],
      "metadata": {
        "id": "PwS1c5kSlse9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 8\n",
        "print(dataset_train[idx][0].size())\n",
        "plt.imshow(dataset_train[idx][0].permute(1,2,0) , cmap=\"gray\")\n",
        "print(dataset_train[idx][1])"
      ],
      "metadata": {
        "id": "l559xY9alFxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "28 * 28"
      ],
      "metadata": {
        "id": "Ena7taiLqCjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Loader"
      ],
      "metadata": {
        "id": "1ShSpMrDpY-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_train = torch.utils.data.DataLoader(dataset_train , batch_size=64 , shuffle = True , num_workers=2)\n",
        "dataloader_test = torch.utils.data.DataLoader(dataset_test , batch_size=64 , shuffle = False , num_workers=2)"
      ],
      "metadata": {
        "id": "eauCox09o6QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(784 , 512),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(512 , 128),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(128 , 10),\n",
        ")"
      ],
      "metadata": {
        "id": "sYtIwQDVprFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "cK7lOGnLrRM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "ZayOGWGZqii0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "metadata": {
        "id": "bg29r6hiq25d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(dataset_train[idx][0])"
      ],
      "metadata": {
        "id": "Fq5VrrjYq-7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "C7sMdECDsazG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "test_loss = []\n",
        "\n",
        "\n",
        "for epoch in range(30):\n",
        "  model.train()\n",
        "  pbar = tqdm(dataloader_train , desc = f\"Training epoch {epoch + 1}\")\n",
        "\n",
        "  sum_correct = 0\n",
        "  sum_sample = 0\n",
        "  sum_loss = 0\n",
        "  for x , y in pbar:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(x)\n",
        "    loss_value = loss_function(output , y)\n",
        "    pbar.set_postfix_str(f\"Loss = {loss_value:.3f}\")\n",
        "    loss_value.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    sum_correct += (output.argmax(axis = 1) == y).sum().item()\n",
        "    sum_sample += len(y)\n",
        "    sum_loss += loss_value * len(y)\n",
        "\n",
        "  train_loss.append(sum_loss / sum_sample)\n",
        "  train_acc.append(sum_correct / sum_sample)\n",
        "  print(f\"Average train loss: {sum_loss / sum_sample:.4f}\")\n",
        "  print(f\"Average train Accuracy: {sum_correct / sum_sample:.4f}\")\n",
        "  print(\"--------------------------------\")\n",
        "\n",
        "  pbar = tqdm(dataloader_test , desc  = f\"Testing in epoch {epoch + 1}\" )\n",
        "\n",
        "  for x , y in pbar:\n",
        "    model.eval()\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(x)\n",
        "        loss_value = loss_function(output , y)\n",
        "        pbar.set_postfix_str(f\"Loss = {loss_value:.3f}\")\n",
        "        sum_sample += len(y)\n",
        "        sum_loss += loss_value.item() * len(y)\n",
        "        sum_correct += (y == output.argmax(axis = 1)).sum().item()\n",
        "\n",
        "  test_loss.append((sum_loss / sum_sample))\n",
        "  test_acc.append((sum_correct/sum_sample))\n",
        "  print(f\"Average test loss: {sum_loss / sum_sample :.4f}\")\n",
        "  print(f\"Average test Accuracy: {sum_correct / sum_sample:.4f}\")\n",
        "  print(\"--------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Dg09Q4qEreew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss"
      ],
      "metadata": {
        "id": "Fi54SNxn3CMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = list(map(lambda x:x.item() , test_loss))\n",
        "train_loss = list(map(lambda x:x.item() , train_loss))"
      ],
      "metadata": {
        "id": "2eG9JgnX0_J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_acc , label = \"Train Acc\")\n",
        "plt.plot(test_acc , label = \"Test Acc\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.ylabel(\"Epoch\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_loss , label = \"Train Loss\")\n",
        "plt.plot(test_loss , label = \"Test Loss\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.xlabel(\"Loss\")\n",
        "plt.ylabel(\"Epoch\")\n",
        "\n"
      ],
      "metadata": {
        "id": "SkGWTgFjsXrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(dataset_test[0][0].permute(1,2,0))\n",
        "print(dataset_test[0][1])\n"
      ],
      "metadata": {
        "id": "Ycrix8an0eTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_DSO835L_iAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uncorrect = []\n",
        "correct = []\n",
        "for x , y in dataset_test:\n",
        "  x = x.to(device)\n",
        "\n",
        "  output = model(x)\n",
        "  output = output.argmax()\n",
        "\n",
        "  if y != output:\n",
        "    uncorrect.append((x , y , output.item()))\n",
        "  elif y == output:\n",
        "    correct.append((x , y , output.item()))\n",
        "\n"
      ],
      "metadata": {
        "id": "Cg3N3niQ72sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8NMLDLHG9pEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_uncorrect(idx:int):\n",
        "\n",
        "  print(f\"Real label = {uncorrect[idx][1]}\")\n",
        "  print(f\"Predicted label = {uncorrect[idx][2]}\")\n",
        "  plt.imshow(uncorrect[idx][0].to('cpu').permute(1,2,0) , cmap=\"gray\")\n",
        "\n",
        "def show_correct(idx:int):\n",
        "\n",
        "  print(f\"Real label = {correct[idx][1]}\")\n",
        "  print(f\"Predicted label = {correct[idx][2]}\")\n",
        "  plt.imshow(correct[idx][0].to('cpu').permute(1,2,0) , cmap=\"gray\")\n",
        "\n"
      ],
      "metadata": {
        "id": "F1DLb4E685Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_uncorrect(9)"
      ],
      "metadata": {
        "id": "Gw6aDiE-9biV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_correct(9)"
      ],
      "metadata": {
        "id": "wUELjL5J_GSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}